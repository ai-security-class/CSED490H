<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Schedule | CSED490H</title>
    <link rel="icon" type="image/png" href="https://sangdon.github.io/media/icon_hu_cf4646339ec87b25.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Merriweather:wght@700;900&family=Source+Sans+3:wght@400;600;700&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="../assets/css/style.css" />
  </head>
  <body>
    <header class="site-header">
      <div class="wrap header-inner">
        <a class="brand" href="/CSED490H/2026/">CSED490H · AI Security<small>POSTECH CSE / GSAI</small></a>
      </div>
    </header>

    <main class="wrap">
      <section class="hero hero-compact">
        <h1>Course Schedule</h1>
      </section>

      <section class="card">
        <table>
          <thead>
            <tr>
              <th style="width: 90px">Week</th>
              <th>Topics</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><strong>1</strong></td><td>Introduction to AI Security</td></tr>
            <tr><td><strong>2</strong></td><td>Preliminary: Neural Networks / SGD<br />Inference-time Attacks: Adversarial Examples / Adversarial Patches / Transfer Attacks</td></tr>
            <tr><td><strong>3</strong></td><td>Preliminary: Transformers / LLMs / LCMs / LRMs<br />Preliminary: RAG</td></tr>
            <tr><td><strong>4</strong></td><td>Student Presentation and Discussion on HW 1</td></tr>
            <tr><td><strong>5</strong></td><td>Preliminary: Diffusion Models<br />Preliminary: Vision-Language-Action Models</td></tr>
            <tr><td><strong>6</strong></td><td>Preliminary: Optimization for Whitebox Victim Models -- Prompt tuning methods (e.g., LoRA)<br />Preliminary: Optimization for Blackbox Victim Models -- Zero-th Order Optimization</td></tr>
            <tr><td><strong>7</strong></td><td>Preliminary: Optimization for Blackbox Victim Models -- RL / Policy Optimization<br />Inference-time Attacks: Prompt Leaking, Prompt Injection, Jailbreaking</td></tr>
            <tr><td><strong>8</strong></td><td>Preliminary: Agentic AI / Tool-calling Agents<br />Inference-time Attacks: Current Trends on Red Teaming</td></tr>
            <tr><td><strong>9</strong></td><td>Student Presentation and Discussion on HW 2</td></tr>
            <tr><td><strong>10</strong></td><td>Introduction to OpenClaw</td></tr>
            <tr><td><strong>11</strong></td><td>Training-set Attacks: membership inference attacks<br />Training-set Attacks: data poisoning attacks</td></tr>
            <tr><td><strong>12</strong></td><td>Model Attacks: model extraction attacks</td></tr>
            <tr><td><strong>13</strong></td><td>Final Remarks: Overview on defense methods</td></tr>
            <tr><td><strong>14</strong></td><td>Student Presentation and Discussion on Final Projects</td></tr>
            <tr><td><strong>15</strong></td><td>Student Presentation and Discussion on Final Projects</td></tr>
          </tbody>
        </table>
      </section>
    </main>

    <footer class="site-footer">
      <div class="wrap">CSED490H · AI Security · POSTECH</div>
    </footer>
  </body>
</html>
